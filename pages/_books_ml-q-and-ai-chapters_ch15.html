<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width initial-scale=1" name="viewport">
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="Sebastian Raschka" name="author"/>
<meta content="
      Chapter 15
    " property="og:title"/>
<meta content="
        I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.

      " property="og:description"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch15/" property="og:url">
<meta content="Sebastian Raschka, PhD" property="og:site_name">
<meta content="en_US" property="og:locale">
<meta content="@rasbt" name="twitter:site">
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="twitter:description"/>
<meta content="article" property="og:type"/>
<meta content="" property="article:published_time"/>
<meta content="@rasbt" name="twitter:creator"/>
<meta content="Chapter 15" name="twitter:title"/>
<meta content="summary" name="twitter:card"/>
<meta content="" name="twitter:image"/>
<title>Chapter 15</title>
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="description"/>
<link href=" /css/combined_direct_no_sass.css" rel="stylesheet"/>
<link href=" /css/fork-awesome.min.css" rel="stylesheet"/>
<meta content="Chapter 15" property="og:title"/>
<meta content="article" property="og:type"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch15/" property="og:url"/>
<meta content="" property="og:image"/>
<meta content="" property="og:description"/>
<meta content="Sebastian Raschka, PhD" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<meta content="" property="fb:admins"/>
<meta content="" property="fb:app_id"/>
<link href="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch15/" rel="canonical"/>
<link href="/images/favicons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/favicons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/favicons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/site.webmanifest" rel="manifest"/>
<link color="#5bbad5" href="/images/favicons/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#ffc40d" name="msapplication-TileColor"/>
<meta content="#ffffff" name="theme-color"/>
</meta></meta></meta></meta></meta></head>
<body>
<img alt="Ahead of AI logo" src="../images/ahead-of-ai-icon.png" style="display: none;"/>
<header class="site-header">
<div class="site-title" style="text-decoration: none; margin-top: 2em;">
<a href="/"><span style="color:black">Sebastian</span> <span style="color:#c5050c">Raschka</span> </a>
<a href="https://x.com/rasbt"><img alt="Twitter/X icon" height="20" src="../images/twitter-bw.jpg" style="padding-left:20px;"/></a>
<!--<a href="https://threads.net/@sebastianraschka"><img src="/images/logos/threads-logo-alt-small.png" height="20" style="padding-left:5px;" alt="Threads icon"></a>-->
<a href="https://www.linkedin.com/in/sebastianraschka/"><img alt="LinkedIn Icon" height="20" src="../images/linkedin-bw.jpg" style="padding-left:5px;"/></a>
<a href="https://github.com/rasbt"><img alt="GitHub icon" height="20" src="../images/github-bw.jpg" style="padding-left:5px;"/></a>
</div>
<!--  <div style="width:100%;height:50;float:left;margin-bottom:10px;">
        &nbsp;<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-bw.jpg" height="20"></a>-->
<!-- &nbsp;<a href="https://www.buymeacoffee.com/rasbt"><img src="/images/logos/coffee-bw.jpg" height="20"></a>-->
<!--&nbsp;<a href="https://mastodon.social/@SebRaschka"><img src="/images/logos/mastodon-bw.jpg" height="20"></a>-->
<!-- </div>-->
<div class="wrapper">
<nav class="site-nav">
<a class="menu-icon" href="#">
<svg viewbox="0 0 18 15">
<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" fill="#424242"></path>
<path d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" fill="#424242"></path>
<path d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" fill="#424242"></path>
</svg>
</a>
<div class="trigger">
<!--<script type="text/javascript">
          var total_images = 2;
          var random_number = Math.floor((Math.random()*total_images));
          var random_img = new Array();
          random_img[0] = '<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-1.jpg" height="20"></a>';
          random_img[1] = '<a href="https://linkedin.com/in/sebastianraschka"><img src="/images/logos/linkedin-1.jpg" height="20"></a>';
          document.write(random_img[random_number]);
          </script>-->
<span style="padding-left:0px;margin-left:0px;"></span>
<a class="page-link" href="https://magazine.sebastianraschka.com"><span style="color:#c5050c;"><img alt="Ahead of AI Logo" height="20" src="../images/ahead-of-ai-icon.png"/> Blog</span></a>
<!--<a class="page-link" href="/blog/index.html">Blog</a>-->
<a class="page-link" href="/books">Books</a>
<!--<a class="page-link" href="/newsletter">AI Newsletter</a>-->
<!--<a class="page-link" href="/teaching">Courses</a>-->
<a class="page-link" href="https://github.com/rasbt/LLMs-from-scratch">LLMs From Scratch</a>
<!--<a class="page-link" href="/publications">Research</a>-->
<a class="page-link" href="/elsewhere">Talks</a>
<a class="page-link" href="/contact">Contact</a>
<a class="page-link" href="/resources">More</a>
</div>
</nav>
</div>
</header>
<div class="page-content">
<div class="wrapper">
<!-- MathJax script for LaTeX rendering -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- Open Graph Metadata -->
<meta content="article" property="og:type"/>
<meta content="Chapter 15" property="og:title"/>
<meta content="" property="og:description"/>
<meta content="https://sebastianraschka.com" property="og:image"/>
<meta content="" property="og:image:alt"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch15/" property="og:url"/>
<meta content="Sebastian Raschka's Blog" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<!-- Twitter Metadata -->
<meta content="summary_large_image" name="twitter:card"/>
<meta content="Chapter 15" name="twitter:title"/>
<meta content="" name="twitter:description"/>
<meta content="https://sebastianraschka.com" name="twitter:image"/>
<meta content="" name="twitter:image:alt"/>
<div class="post">
<header class="post-header">
<h1 class="post-title" style="text-align: left;">Machine Learning Q and AI</h1>
<h2 class="post-subtitle">30 Essential Questions and Answers on Machine Learning and AI</h2>
<p>
      By Sebastian Raschka. <a href="#table-of-contents">Free to read</a>.
      Published by <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>.<br/>
      Copyright Â© 2024-2025 by Sebastian Raschka.
    </p>
<p>
<img alt="Machine Learning and Q and AI" class="right-image-shadow-30" src="../images/2023-ml-ai-beyond.jpg"/>
</p>
<blockquote>
      Machine learning and AI are moving at a rapid pace. Researchers and practitioners are constantly struggling to keep up with the breadth of concepts and techniques. This book provides bite-sized bits of knowledge for your journey from machine learning beginner to expert, covering topics from various machine learning areas. Even experienced machine learning researchers and practitioners will encounter something new that they can add to their arsenal of techniques.
    </blockquote>
<br/>
<p><strong>ð Print Book:</strong><br/>
<a href="https://amzn.to/4488ahe">Amazon</a><br/>
<a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</p>
<p><strong>ð Read Online:</strong><br/>
<a href="#table-of-contents">Full Book (Free)</a>
</p>
</header>
<article class="post-content">
<!-- Optional: Anchor Headings -->
<h1 id="chapter-15-data-augmentation-for-text">
        
        
          Chapter 15: Data Augmentation for Text <a href="#chapter-15-data-augmentation-for-text"></a>
</h1>
<p><span id="ch15" label="ch15"></span></p>
<p><strong>How is data augmentation useful, and what are the most common
augmentation techniques for text data?</strong></p>
<p>Data augmentation is useful for artificially increasing dataset sizes to
improve model performance, such as by reducing the degree of
overfitting, as discussed in
ChapterÂ <a data-reference="ch05" data-reference-type="ref" href="../ch05">[ch05]</a>. This includes techniques often used in
computer vision models, like rotation, scaling, and flipping.</p>
<p>Similarly, there are several techniques for augmenting text data. The
most common include synonym replacement, word deletion, word position
swapping, sentence shuffling, noise injection, back translation, and
text generated by LLMs. This chapter discusses each of these, with
optional code examples in the <em>supplementary/q15-text-augment</em> subfolder
at <a href="https://github.com/rasbt/MachineLearning-QandAI-book">https://github.com/rasbt/MachineLearning-QandAI-book</a>.</p>
<h2 id="synonym-replacement">
        
        
          Synonym Replacement <a href="#synonym-replacement"></a>
</h2>
<p>In <em>synonym replacement</em>, we randomly choose words in a sentenceâoften
nouns, verbs, adjectives, and adverbsâand replace them with synonyms.
For example, we might begin with the sentence âThe cat quickly jumped
over the lazy dog,â and then augment the sentence as follows: âThe cat
rapidly jumped over the idle dog.â</p>
<p>Synonym replacement can help the model learn that different words can
have similar meanings, thereby improving its ability to understand and
generate text. In practice, synonym replacement often relies on a
thesaurus such as WordNet. However, using this technique requires care,
as not all synonyms are interchangeable in all contexts. Most automatic
text replacement tools have settings for adjusting replacement frequency
and similarity thresholds. However, automatic synonym replacement is not
perfect, and you might want to apply post-processing checks to filter
out replacements that might not make sense.</p>
<h2 id="word-deletion">
        
        
          Word Deletion <a href="#word-deletion"></a>
</h2>
<p><em>Word deletion</em> is another data augmentation technique to help models
learn. Unlike synonym replacement, which alters the text by substituting
words with their synonyms, word deletion involves removing certain words
from the text to create new variants while trying to maintain the
overall meaning of the sentence. For example, we might begin with the
sentence âThe cat quickly jumped over the lazy dogâ and then remove the
word <em>quickly</em>: âThe cat jumped over the lazy dog.â</p>
<p>By randomly deleting words in the training data, we teach the model to
make accurate predictions even when some information is missing. This
can make the model more robust when encountering incomplete or noisy
data in real-world scenarios. Also, by deleting nonessential words, we
may teach the model to focus on key aspects of the text that are most
relevant to the task at hand.</p>
<p>However, we must be careful not to remove critical words that may
significantly alter a sentenceâs meaning. For example, it would be
suboptimal to remove the word <em>cat</em> in the previous sentence: âThe
quickly jumped over the lazy dog.â We must also choose the deletion rate
carefully to ensure that the text still makes sense after words have
been removed. Typical deletion rates might range from 10 percent to 20
percent, but this is a general guideline and could vary significantly
based on the specific use case.</p>
<h2 id="word-position-swapping">
        
        
          Word Position Swapping <a href="#word-position-swapping"></a>
</h2>
<p>In <em>word position swapping</em>, also known as <em>word shuffling</em> or
<em>permutation</em>, the positions of words in a sentence are swapped or
rearranged to create new versions of the sentence. If we begin with âThe
cat quickly jumped over the lazy dog,â we might swap the positions of
some words to get the following: âQuickly the cat jumped the over lazy
dog.â</p>
<p>While these sentences may sound grammatically incorrect or strange in
English, they provide valuable training information for data
augmentation because the model can still recognize the important words
and their associations with each other. However, this method has its
limitations. For example, shuffling words too much or in certain ways
can drastically change the meaning of a sentence or make it completely
nonsensical. Moreover, word shuffling may interfere with the modelâs
learning process, as the positional relationships between certain words
can be vital in these contexts.</p>
<h2 id="sentence-shuffling">
        
        
          Sentence Shuffling <a href="#sentence-shuffling"></a>
</h2>
<p>In <em>sentence shuffling</em>, entire sentences within a paragraph or a
document are rearranged to create new versions of the input text. By
shuffling sentences within a document, we expose the model to different
arrangements of the same content, helping it learn to recognize thematic
elements and key concepts rather than relying on specific sentence
order. This promotes a more robust understanding of the documentâs
overall topic or category. Consequently, this technique is particularly
useful for tasks that deal with document-level analysis or
paragraph-level understanding, such as document classification, topic
modeling, or text summarization.</p>
<p>In contrast to the aforementioned word-based methods (word position
swapping, word deletion, and synonym replacement), sentence shuffling
maintains the internal structure of individual sentences. This avoids
the problem of altering word choice or order such that sentences become
grammatically incorrect or change meaning entirely.</p>
<p>Sentence shuffling is useful when the order of sentences is not crucial
to the overall meaning of the text. Still, it may not work well if the
sentences are logically or chronologically connected. For example,
consider the following paragraph: âI went to the supermarket. Then I
bought ingredients to make pizza. Afterward, I made some delicious
pizza.â Reshuffling these sentences as follows disrupts the logical and
temporal progression of the narrative: âAfterward, I made some delicious
pizza. Then I bought ingredients to make pizza. I went to the
supermarket.â</p>
<h2 id="noise-injection">
        
        
          Noise Injection <a href="#noise-injection"></a>
</h2>
<p><em>Noise injection</em> is an umbrella term for techniques used to alter text
in various ways and create variation in the texts. It may refer either
to the methods described in the previous sections or to character-level
techniques such as inserting random letters, characters, or typos, as
shown in the following examples:</p>
<p>Random character insertion
âThe cat qzuickly jumped over the lazy dog.â (Inserted a <em>z</em> in the word
<em>quickly</em>.)</p>
<p>Random character deletion
âThe cat quickl jumped over the lazy dog.â (Deleted <em>y</em> from the word
<em>quickly</em>.)</p>
<p>Typo introduction
âThe cat qickuly jumped over the lazy dog.â
(Introduced a typo in <em>quickly</em>, changing it to <em>qickuly</em>.)</p>
<p>These modifications are beneficial for tasks that involve spell-checking
and text correction, but they can also help make the model more robust
to imperfect inputs.</p>
<h2 id="back-translation">
        
        
          Back Translation <a href="#back-translation"></a>
</h2>
<p><em>Back translation</em> is one of the most widely used techniques to create
variation in texts. Here, a sentence is first translated from the
original language into one or more different languages, and then it is
translated back into the original language. Translating back and forth
often results in sentences that are semantically similar to the original
sentence but have slight variations in structure, vocabulary, or
grammar. This generates additional, diverse examples for training
without altering the overall meaning.</p>
<p>For example, say we translate âThe cat quickly jumped over the lazy dogâ
into German. We might get âDie Katze sprang schnell Ã¼ber den faulen
Hund.â We could then translate this German sentence back into English to
get âThe cat jumped quickly over the lazy dog.â</p>
<p>The degree to which a sentence changes through backtranslation depends on the
languages used and the specifics of the machine translation model. In this example,
the sentence remains verys imilar. However, in other cases or with other languages,
you might see more significant changes in wording or sentence structure while maintaining the same overall meaning.</p>
<p>This method requires access to reliable machine translation models or
services, and care must be taken to ensure that the back-translated
sentences retain the essential meaning of the original sentences.</p>
<h2 id="synthetic-data">
        
        
          Synthetic Data <a href="#synthetic-data"></a>
</h2>
<p><em>Synthetic data generation</em> is an umbrella term that describes methods
and techniques used to create artificial data that mimics or replicates
the structure of real-world data. All methods discussed in this chapter
can be considered synthetic data generation techniques since they
generate new data by making small changes to existing data, thus
maintaining the overall meaning while creating something new.</p>
<p>Modern techniques to generate synthetic data now also include using
decoder-style LLMs such as GPT (decoder-style LLMs are discussed in more
detail in ChapterÂ <a data-reference="ch17" data-reference-type="ref" href="../ch17">[ch17]</a>). We can use these models to generate
new data from scratch by using âcomplete the sentenceâ or âgenerate
example sentencesâ prompts, among others. We can also use LLMs as
alternatives to back translation, prompting them to rewrite sentences as
shown in FigureÂ <a data-reference="fig:ch15-fig01" data-reference-type="ref" href="#fig:ch15-fig01">1.1</a>.</p>
<figure id="fig:ch15-fig01">
<figcaption>Using an LLM to rewrite a sentence</figcaption>
</figure>
<p>Note that an LLM, as shown in
FigureÂ <a data-reference="fig:ch15-fig01" data-reference-type="ref" href="#fig:ch15-fig01">1.1</a>, runs in a nondeterministic mode
by default, which means we can prompt it multiple times to obtain a
variety of rewritten sentences.</p>
<h2 id="recommendations">
        
        
          Recommendations <a href="#recommendations"></a>
</h2>
<p>The data augmentation techniques discussed in this chapter are commonly
used in text classification, sentiment analysis, and other NLP tasks
where the amount of available labeled data might be limited.</p>
<p>LLMs are usually pretrained on such a vast and diverse dataset that they
may not rely on these augmentation techniques as extensively as in
other, more specific NLP tasks. This is because LLMs aim to capture the
statistical properties of the language, and the vast amount of data on
which they are trained often provides a sufficient variety of contexts
and expressions. However, in the fine-tuning stages of LLMs, where a
pretrained model is adapted to a specific task with a smaller,
task-specific dataset, data augmentation techniques might become more
relevant again, mainly if the task-specific labeled dataset size is
limited.</p>
<h3 id="exercises">
        
        
          Exercises <a href="#exercises"></a>
</h3>
<p>15-1. Can the use of text data augmentation
help with privacy concerns?</p>
<p>15-2. What are
some instances where data augmentation may not be beneficial for a
specific task?</p>
<h2 id="references">
        
        
          References <a href="#references"></a>
</h2>
<ul>
<li>The WordNet thesaurus: George A. Miller, âWordNet: A Lexical Database
for Englishâ (1995), <a href="https://dl.acm.org/doi/10.1145/219717.219748">https://dl.acm.org/doi/10.1145/219717.219748</a>.</li>
</ul>
</article>
<br/>
<hr/>
<div class="book-promotion" style="margin-top: 50px;">
<h2>Support the Author</h2>
<p>You can support the author in the following ways:</p>
<ul>
<li>
        Subscribe to <a href="https://magazine.sebastianraschka.com">Sebastian's Substack blog</a>
</li>
<li>
        Purchase a copy on
        <a href="https://amzn.to/4488ahe">Amazon</a> or
        <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</li>
<li>
        Write an <a href="https://amzn.to/4488ahe">Amazon review</a>
</li>
</ul>
</div>
<div style="margin-bottom: 50px;"></div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="wrapper">
<div class="footer-col-wrapper">
<div class="footer-col social-col">
<a href="https://magazine.sebastianraschka.com"><span><i class="fa fa-rss fa-2x"></i></span> </a>
<a href="/contact"><span><i class="fa fa-envelope fa-2x"></i></span> </a>
<a href="https://twitter.com/rasbt"> <span><i class="fa fa-twitter fa-2x"></i></span> </a>
<a href="https://youtube.com/c/SebastianRaschka"><span><i class="fa fa-youtube fa-2x"></i></span> </a>
<a href="https://github.com/rasbt"><span><i class="fa fa-github fa-2x"></i> </span></a>
<a href="https://scholar.google.com/citations?user=X4RCC0IAAAAJ&amp;hl=enrasbt"><span><i class="fa fa-google fa-2x"></i> </span></a>
<a href="https://linkedin.com/in/sebastianraschka"><span><i class="fa fa-linkedin fa-2x"></i> </span></a>
</div>
<div class="footer-col copyright-col">
<p>© 2013-2025 Sebastian Raschka</p>
</div>
</div>
</div>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BYQXBRPK81"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BYQXBRPK81');
</script>
</footer>

<script src="/js/anchor.min.js" type="text/javascript"></script>
<script>
    var selector = 'h2, h3, h4, h5, h6';
    /*
    anchors.options = {
      icon: '#',
      visible: 'always',
      placement: 'left',
      class: 'bb-anchor'
    }
    */
    anchors.add(selector);
  </script>
</body>
</html>
