<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width initial-scale=1" name="viewport">
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="Sebastian Raschka" name="author"/>
<meta content="
      Chapter 26
    " property="og:title"/>
<meta content="
        I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.

      " property="og:description"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch26/" property="og:url">
<meta content="Sebastian Raschka, PhD" property="og:site_name">
<meta content="en_US" property="og:locale">
<meta content="@rasbt" name="twitter:site">
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="twitter:description"/>
<meta content="article" property="og:type"/>
<meta content="" property="article:published_time"/>
<meta content="@rasbt" name="twitter:creator"/>
<meta content="Chapter 26" name="twitter:title"/>
<meta content="summary" name="twitter:card"/>
<meta content="" name="twitter:image"/>
<title>Chapter 26</title>
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="description"/>
<link href=" /css/combined_direct_no_sass.css" rel="stylesheet"/>
<link href=" /css/fork-awesome.min.css" rel="stylesheet"/>
<meta content="Chapter 26" property="og:title"/>
<meta content="article" property="og:type"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch26/" property="og:url"/>
<meta content="" property="og:image"/>
<meta content="" property="og:description"/>
<meta content="Sebastian Raschka, PhD" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<meta content="" property="fb:admins"/>
<meta content="" property="fb:app_id"/>
<link href="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch26/" rel="canonical"/>
<link href="/images/favicons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/favicons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/favicons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/site.webmanifest" rel="manifest"/>
<link color="#5bbad5" href="/images/favicons/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#ffc40d" name="msapplication-TileColor"/>
<meta content="#ffffff" name="theme-color"/>
</meta></meta></meta></meta></meta></head>
<body>
<img alt="Ahead of AI logo" src="../images/ahead-of-ai-icon.png" style="display: none;"/>
<header class="site-header">
<div class="site-title" style="text-decoration: none; margin-top: 2em;">
<a href="/"><span style="color:black">Sebastian</span> <span style="color:#c5050c">Raschka</span> </a>
<a href="https://x.com/rasbt"><img alt="Twitter/X icon" height="20" src="../images/twitter-bw.jpg" style="padding-left:20px;"/></a>
<!--<a href="https://threads.net/@sebastianraschka"><img src="/images/logos/threads-logo-alt-small.png" height="20" style="padding-left:5px;" alt="Threads icon"></a>-->
<a href="https://www.linkedin.com/in/sebastianraschka/"><img alt="LinkedIn Icon" height="20" src="../images/linkedin-bw.jpg" style="padding-left:5px;"/></a>
<a href="https://github.com/rasbt"><img alt="GitHub icon" height="20" src="../images/github-bw.jpg" style="padding-left:5px;"/></a>
</div>
<!--  <div style="width:100%;height:50;float:left;margin-bottom:10px;">
        &nbsp;<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-bw.jpg" height="20"></a>-->
<!-- &nbsp;<a href="https://www.buymeacoffee.com/rasbt"><img src="/images/logos/coffee-bw.jpg" height="20"></a>-->
<!--&nbsp;<a href="https://mastodon.social/@SebRaschka"><img src="/images/logos/mastodon-bw.jpg" height="20"></a>-->
<!-- </div>-->
<div class="wrapper">
<nav class="site-nav">
<a class="menu-icon" href="#">
<svg viewbox="0 0 18 15">
<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" fill="#424242"></path>
<path d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" fill="#424242"></path>
<path d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" fill="#424242"></path>
</svg>
</a>
<div class="trigger">
<!--<script type="text/javascript">
          var total_images = 2;
          var random_number = Math.floor((Math.random()*total_images));
          var random_img = new Array();
          random_img[0] = '<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-1.jpg" height="20"></a>';
          random_img[1] = '<a href="https://linkedin.com/in/sebastianraschka"><img src="/images/logos/linkedin-1.jpg" height="20"></a>';
          document.write(random_img[random_number]);
          </script>-->
<span style="padding-left:0px;margin-left:0px;"></span>
<a class="page-link" href="https://magazine.sebastianraschka.com"><span style="color:#c5050c;"><img alt="Ahead of AI Logo" height="20" src="../images/ahead-of-ai-icon.png"/> Blog</span></a>
<!--<a class="page-link" href="/blog/index.html">Blog</a>-->
<a class="page-link" href="/books">Books</a>
<!--<a class="page-link" href="/newsletter">AI Newsletter</a>-->
<!--<a class="page-link" href="/teaching">Courses</a>-->
<a class="page-link" href="https://github.com/rasbt/LLMs-from-scratch">LLMs From Scratch</a>
<!--<a class="page-link" href="/publications">Research</a>-->
<a class="page-link" href="/elsewhere">Talks</a>
<a class="page-link" href="/contact">Contact</a>
<a class="page-link" href="/resources">More</a>
</div>
</nav>
</div>
</header>
<div class="page-content">
<div class="wrapper">
<!-- MathJax script for LaTeX rendering -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- Open Graph Metadata -->
<meta content="article" property="og:type"/>
<meta content="Chapter 26" property="og:title"/>
<meta content="" property="og:description"/>
<meta content="https://sebastianraschka.com" property="og:image"/>
<meta content="" property="og:image:alt"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch26/" property="og:url"/>
<meta content="Sebastian Raschka's Blog" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<!-- Twitter Metadata -->
<meta content="summary_large_image" name="twitter:card"/>
<meta content="Chapter 26" name="twitter:title"/>
<meta content="" name="twitter:description"/>
<meta content="https://sebastianraschka.com" name="twitter:image"/>
<meta content="" name="twitter:image:alt"/>
<div class="post">
<header class="post-header">
<h1 class="post-title" style="text-align: left;">Machine Learning Q and AI</h1>
<h2 class="post-subtitle">30 Essential Questions and Answers on Machine Learning and AI</h2>
<p>
      By Sebastian Raschka. <a href="#table-of-contents">Free to read</a>.
      Published by <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>.<br/>
      Copyright Â© 2024-2025 by Sebastian Raschka.
    </p>
<p>
<img alt="Machine Learning and Q and AI" class="right-image-shadow-30" src="../images/2023-ml-ai-beyond.jpg"/>
</p>
<blockquote>
      Machine learning and AI are moving at a rapid pace. Researchers and practitioners are constantly struggling to keep up with the breadth of concepts and techniques. This book provides bite-sized bits of knowledge for your journey from machine learning beginner to expert, covering topics from various machine learning areas. Even experienced machine learning researchers and practitioners will encounter something new that they can add to their arsenal of techniques.
    </blockquote>
<br/>
<p><strong>ð Print Book:</strong><br/>
<a href="https://amzn.to/4488ahe">Amazon</a><br/>
<a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</p>
<p><strong>ð Read Online:</strong><br/>
<a href="#table-of-contents">Full Book (Free)</a>
</p>
</header>
<article class="post-content">
<!-- Optional: Anchor Headings -->
<h1 id="chapter-26-confidence-intervals-vs-conformal-predictions">
        
        
          Chapter 26: Confidence Intervals vs. Conformal Predictions <a href="#chapter-26-confidence-intervals-vs-conformal-predictions"></a>
</h1>
<p><span id="ch26" label="ch26"></span></p>
<p><strong>What are the differences between confidence intervals and conformal
predictions, and when do we use one over the other?</strong></p>
<p>Confidence intervals and conformal predictions are both statistical
methods to estimate the range of plausible values for an unknown
population parameter. As discussed in
ChapterÂ <a data-reference="ch25" data-reference-type="ref" href="../ch25">[ch25]</a>, a confidence interval quantifies the
level of confidence that a population parameter lies within an interval.
For instance, a 95 percent confidence interval for the mean of a
population means that if we were to take many samples from the
population and calculate the 95 percent confidence interval for each
sample, we would expect the true population mean (average) to lie within
these intervals 95 percent of the time.
ChapterÂ <a data-reference="ch25" data-reference-type="ref" href="../ch25">[ch25]</a> covered several techniques for applying
this method to estimate the prediction performance of machine learning
models. Conformal predictions, on the other hand, are commonly used for
creating prediction intervals, which are designed to cover a true
outcome with a certain probability.</p>
<p>This chapter briefly explains what a prediction interval is and how it
differs from confidence intervals, and then it explains how conformal
predictions are, loosely speaking, a method for constructing prediction
intervals.</p>
<h2 id="confidence-intervals-and-prediction-intervals">
        
        
          Confidence Intervals and Prediction Intervals <a href="#confidence-intervals-and-prediction-intervals"></a>
</h2>
<p>Whereas a confidence interval focuses on parameters that characterize a
population as a whole, a <em>prediction interval</em> provides a range of
values for a single predicted target value. For example, consider the
problem of predicting peopleâs heights. Given a sample of 10,000 people
from the population, we might conclude that the mean (average) height is
5 feet, 7 inches. We might also calculate a 95 percent confidence
interval for this mean, ranging from 5 feet, 6 inches to 5 feet, 8
inches.</p>
<p>A <em>prediction interval</em>, however, is concerned with estimating not the
height of the population but the height of an individual person. For
example, given a weight of 185 pounds, a given personâs prediction
interval may fall between 5 feet 8 inches and 6 feet.</p>
<p>In a machine learning model context, we can use confidence intervals to
estimate a population parameter such as the accuracy of a model (which
refers to the performance on all possible prediction scenarios). In
contrast, a prediction interval estimates the range of output values for
a single given input example.</p>
<h2 id="prediction-intervals-and-conformal-predictions">
        
        
          Prediction Intervals and Conformal Predictions <a href="#prediction-intervals-and-conformal-predictions"></a>
</h2>
<p>Both conformal predictions and prediction intervals are statistical
techniques that estimate uncertainty for individual model predictions,
but they do so in different ways and under different assumptions.</p>
<p>While prediction intervals often assume a particular data distribution
and are tied to a specific type of model, conformal prediction methods
are distribution free and can be applied to any machine learning
algorithm.</p>
<p>In short, we can think of conformal predictions as a more flexible and
generalizable form of prediction intervals. However, conformal
predictions often require more computational resources than traditional
methods for constructing prediction intervals, which involve resampling
or permutation techniques.</p>
<h2 id="prediction-regions-intervals-and-sets">
        
        
          Prediction Regions, Intervals, and Sets <a href="#prediction-regions-intervals-and-sets"></a>
</h2>
<p>In the context of conformal prediction, the terms <em>prediction interval</em>,
<em>prediction set</em>, and <em>prediction region</em> are used to denote the
plausible outputs for a given instance. The type of term used depends on
the nature of the task.</p>
<p>In regression tasks where the output is a continuous variable, a
<em>prediction interval</em> provides a range within which the true value is
expected to fall with a certain level of confidence. For example, a
model might predict that the price of a house is between $200,000 and
$250,000.</p>
<p>In classification tasks, where the output is a discrete variable (the
class labels), a <em>prediction set</em> includes all class labels that are
considered plausible predictions for a given instance. For example, a
model might predict that an image depicts either a cat, dog, or bird.</p>
<p><em>Prediction region</em> is a more general term that can refer to either a
prediction interval or a prediction set. It describes the set of outputs
considered plausible by the model.</p>
<h2 id="computing-conformal-predictions">
        
        
          Computing Conformal Predictions <a href="#computing-conformal-predictions"></a>
</h2>
<p>Now that weâve introduced the difference between confidence intervals
and prediction regions and learned how conformal prediction methods are
related to prediction intervals, how exactly do conformal predictions
work?</p>
<p>In short, conformal prediction methods provide a framework for creating
prediction regions, sets of potential outcomes for a prediction task.
Given the assumptions and methods used to construct them, these regions
are designed to contain the true outcome with a certain probability.</p>
<p>For classifiers, a prediction region for a given input is a set of
labels such that the set contains the true label with a given confidence
(typically 95 percent), as illustrated in
FigureÂ <a data-reference="fig:ch26-fig01" data-reference-type="ref" href="#fig:ch26-fig01">1.1</a>.</p>
<figure id="fig:ch26-fig01">
<img src="../images/ch26-fig01.png">
<figcaption>Prediction regions for a classification task</figcaption>
</img></figure>
<p>As depicted in
FigureÂ <a data-reference="fig:ch26-fig01" data-reference-type="ref" href="#fig:ch26-fig01">1.1</a>, the ImageNet dataset consists
of a subset of bird species. Some bird species in ImageNet belong to one
of the follow-
Â ing classes: <em>hawk</em>, <em>duck</em>, <em>eagle</em>, or <em>goose</em>. ImageNet also
contains other animals, for example, cats. For a new image to classify
(here, an eagle), the conformal prediction set consists of classes such
that the true label, <em>eagle</em>, is contained within this set with 95
percent probability. Often, this includes closely related classes, such
as <em>hawk</em> and <em>goose</em> in this case. However, the prediction set can also
include less closely related class labels, such as <em>cat</em>.</p>
<p>To sketch the concept of computing prediction regions step by step,
letâs suppose we train a machine learning classifier for images. Before
the modelis trained, the dataset is typically split into three parts: a
training set, a calibration set, and a test set. We use the training set
to train the model and the calibration set to obtain the parameters for
the conformal prediction regions. We can then use the test set to assess
the performance of the conformal predictor. A typical split ratio might
be 60 percent training data,
20 percent calibration data, and 20 percent test data.</p>
<p>The first step after training the model on the training set is to define
a <em>nonconformity measure</em>, a function that assigns a numeric score to
each instance in the calibration set based on how âunusualâ it is. This
could be based on the distance to the classifierâs decision boundary or,
more commonly, 1 minus the predicted probability of a class label. The
higher the score is, the more unusual the instance is.</p>
<p>Before using conformal predictions for new data points, we use the
nonconformity scores from the calibration set to compute a quantile
threshold. This threshold is a probability level such that, for example,
95 percent of the instances in the calibration set (if we choose a 95
percent confidence level) have nonconformity scores below this
threshold. This threshold is then used to determine the prediction
regions for new instances, ensuring that the predictions are calibrated
to the desired confidence level.</p>
<p>Once we have the threshold value, we can compute prediction regions for
new data. Here, for each possible class label (each possible output of
your classifier) for a given instance, we check whether its
nonconformity score is below the threshold. If it is, then we include it
in the prediction set for that instance.</p>
<h2 id="a-conformal-prediction-example">
        
        
          A Conformal Prediction Example <a href="#a-conformal-prediction-example"></a>
</h2>
<p>Letâs illustrate this process of making conformal predictions with an
example using a simple conformal prediction method known as the <em>score
method</em>. Suppose we train a classifier on a training set to distinguish
between three species of birds: sparrows, robins, and hawks. Suppose the
predicted probabilities for a calibration dataset are as follows:</p>
<p>Sparrow
[0.95, 0.9, 0.85, 0.8, 0.75]</p>
<p>Robin
[0.7, 0.65, 0.6, 0.55, 0.5]</p>
<p>Hawk
[0.4, 0.35, 0.3, 0.25, 0.2]</p>
<p>As depicted here, we have a calibration set consisting of 15 examples,
five for each of the three classes. Note that a classifier returns three
probability scores for each training example: one probability
corresponding to each of the three classes (<em>Sparrow</em>, <em>Robin</em>, and
<em>Hawk</em>). Here, however, weâve selected only the probability for the true
class label. For example, we may obtain the values [0.95, 0.02, 0.03]
for the first calibration example with the true label <em>Sparrow</em>. In this
case, we kept only 0.95.</p>
<p>Next, after we obtain the previous probability scores, we can compute
the nonconformity score as 1 minus the probability, as follows:</p>
<p>Sparrow
[0.05, 0.1, 0.15, 0.2, 0.25]</p>
<p>Robin
[0.3, 0.35, 0.4, 0.45, 0.5]</p>
<p>Hawk
[0.6, 0.65, 0.7, 0.75, 0.8]</p>
<p>Considering a confidence level of 0.95, we now select a threshold such
that 95 percent of these nonconformity scores fall below that threshold.
Based on the nonconformity scores in this example, this threshold is
0.8. We can then use this threshold to construct the prediction sets for
new instances we want to classify.</p>
<p>Now suppose we have a new instance (a new image of a bird) that we want
to classify. We calculate the nonconformity score of this new bird
image, assuming it belongs to each bird species (class label) in the
training set:</p>
<p>Sparrow
0.26</p>
<p>Robin
0.45</p>
<p>Hawk
0.9</p>
<p>In this case, the <em>Sparrow</em> and <em>Robin</em> nonconformity scores fall below
the threshold of 0.8. Thus, the prediction set for this input is
[<em>Sparrow</em>, <em>Robin</em>]. In other words, this tells us that, on average,
the true class label is included in the prediction set 95 percent of the
time.</p>
<p>A hands-on code example implementing the score method can be found in
the <em>supplementary/q26_conformal-prediction</em> subfolder at
<a href="https://github.com/rasbt/MachineLearning-QandAI-book">https://github.com/rasbt/MachineLearning-QandAI-book</a>.</p>
<h2 id="the-benefits-of-conformal-predictions">
        
        
          The Benefits of Conformal Predictions <a href="#the-benefits-of-conformal-predictions"></a>
</h2>
<p>In contrast to using class-membership probabilities returned from
classifiers, the major benefits of conformal prediction are its
theoretical guarantees and its generality. Conformal prediction methods
donât make any strong assumptions about the distribution of the data or
the model being used, and they can be applied in conjunction with any
existing machine learning algorithm to provide confidence measures for
predictions.</p>
<p>Confidence intervals have asymptotic coverage guarantees, which means
that the coverage guarantee holds in the limit as the sample (test set)
size goes to infinity. This doesnât necessarily mean that confidence
intervals work for only very large sample sizes, but rather that their
properties are more firmly guaranteed as the sample size increases.
Confidence intervals therefore rely on asymptotic properties, meaning
that their guarantees become more robust as the sample size grows.</p>
<p>In contrast, conformal predictions provide finite-sample guarantees,
ensuring that the coverage probability is achieved for any sample size.
For example, if we specify a 95 percent confidence level for a conformal
prediction method and generate 100 calibration sets with corresponding
prediction sets, the method will include the true class label for 95 out
of the 100 test points. This holds regardless of the size of the
calibration sets.</p>
<p>While conformal prediction has many advantages, it does not always
provide the tightest possible prediction intervals. Sometimes, if the
underlying assumptions of a specific classifier hold, that classifierâs
own probability estimates might offer tighter and more informative
intervals.</p>
<h2 id="recommendations">
        
        
          Recommendations <a href="#recommendations"></a>
</h2>
<p>A confidence interval tells us about our level of uncertainty about the
modelâs properties, such as the prediction accuracy of a classifier. A
prediction interval or conformal prediction output tells us about the
level of uncertainty in a specific prediction from the model. Both are
very important in understanding the reliability and performance of our
model, but they provide different types of information.</p>
<p>For example, a confidence interval for the prediction accuracy of a
model can be helpful for comparing and evaluating models and for
deciding which model to deploy. On the other hand, a prediction interval
can be helpful for using a model in practice and understanding its
predictions. For instance, it can help identify cases where the model is
unsure and may need additional data, human oversight, or a different
approach.</p>
<h3 id="exercises">
        
        
          Exercises <a href="#exercises"></a>
</h3>
<p>26-1. Prediction set sizes can vary between
instances. For example, we may encounter a prediction set size of 1 for
a given instance and for another, a set size of 3. What does the
prediction set size tell us?</p>
<p>26-2.
ChaptersÂ <a data-reference="ch25" data-reference-type="ref" href="../ch25">[ch25]</a>
andÂ <a data-reference="ch26" data-reference-type="ref" href="../ch26">[ch26]</a> focused on classification methods.
Could we use conformal prediction and confidence intervals for
regression too?</p>
<h2 id="references">
        
        
          References <a href="#references"></a>
</h2>
<ul>
<li>
<p>MAPIE is a popular library for conformal predictions in Python:
<a href="https://mapie.readthedocs.io/">https://mapie.readthedocs.io/</a>.</p>
</li>
<li>
<p>For more on the score method used in this chapter: Christoph
Molnar, <em>Introduction to Conformal Prediction with Python</em> (2023),
<a href="https://christophmolnar.com/books/conformal-prediction/">https://christophmolnar.com/books/conformal-prediction/</a>.</p>
</li>
<li>
<p>In addition to the score method, several other variants of confor-
Â mal prediction methods exist. For a comprehensive collection of
conformal prediction literature and resources, see the Awesome
Conformal Prediction page:
<a href="https://github.com/valeman/awesome-conformal-prediction">https://github.com/valeman/awesome-conformal-prediction</a>.</p>
</li>
</ul>
</article>
<br/>
<hr/>
<div class="book-promotion" style="margin-top: 50px;">
<h2>Support the Author</h2>
<p>You can support the author in the following ways:</p>
<ul>
<li>
        Subscribe to <a href="https://magazine.sebastianraschka.com">Sebastian's Substack blog</a>
</li>
<li>
        Purchase a copy on
        <a href="https://amzn.to/4488ahe">Amazon</a> or
        <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</li>
<li>
        Write an <a href="https://amzn.to/4488ahe">Amazon review</a>
</li>
</ul>
</div>
<div style="margin-bottom: 50px;"></div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="wrapper">
<div class="footer-col-wrapper">
<div class="footer-col social-col">
<a href="https://magazine.sebastianraschka.com"><span><i class="fa fa-rss fa-2x"></i></span> </a>
<a href="/contact"><span><i class="fa fa-envelope fa-2x"></i></span> </a>
<a href="https://twitter.com/rasbt"> <span><i class="fa fa-twitter fa-2x"></i></span> </a>
<a href="https://youtube.com/c/SebastianRaschka"><span><i class="fa fa-youtube fa-2x"></i></span> </a>
<a href="https://github.com/rasbt"><span><i class="fa fa-github fa-2x"></i> </span></a>
<a href="https://scholar.google.com/citations?user=X4RCC0IAAAAJ&amp;hl=enrasbt"><span><i class="fa fa-google fa-2x"></i> </span></a>
<a href="https://linkedin.com/in/sebastianraschka"><span><i class="fa fa-linkedin fa-2x"></i> </span></a>
</div>
<div class="footer-col copyright-col">
<p>© 2013-2025 Sebastian Raschka</p>
</div>
</div>
</div>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BYQXBRPK81"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BYQXBRPK81');
</script>
</footer>

<script src="/js/anchor.min.js" type="text/javascript"></script>
<script>
    var selector = 'h2, h3, h4, h5, h6';
    /*
    anchors.options = {
      icon: '#',
      visible: 'always',
      placement: 'left',
      class: 'bb-anchor'
    }
    */
    anchors.add(selector);
  </script>
</body>
</html>
