<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width initial-scale=1" name="viewport">
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="Sebastian Raschka" name="author"/>
<meta content="
      Chapter 04
    " property="og:title"/>
<meta content="
        I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.

      " property="og:description"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch04/" property="og:url">
<meta content="Sebastian Raschka, PhD" property="og:site_name">
<meta content="en_US" property="og:locale">
<meta content="@rasbt" name="twitter:site">
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="twitter:description"/>
<meta content="article" property="og:type"/>
<meta content="" property="article:published_time"/>
<meta content="@rasbt" name="twitter:creator"/>
<meta content="Chapter 04" name="twitter:title"/>
<meta content="summary" name="twitter:card"/>
<meta content="" name="twitter:image"/>
<title>Chapter 04</title>
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="description"/>
<link href=" /css/combined_direct_no_sass.css" rel="stylesheet"/>
<link href=" /css/fork-awesome.min.css" rel="stylesheet"/>
<meta content="Chapter 04" property="og:title"/>
<meta content="article" property="og:type"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch04/" property="og:url"/>
<meta content="" property="og:image"/>
<meta content="" property="og:description"/>
<meta content="Sebastian Raschka, PhD" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<meta content="" property="fb:admins"/>
<meta content="" property="fb:app_id"/>
<link href="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch04/" rel="canonical"/>
<link href="/images/favicons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/favicons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/favicons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/site.webmanifest" rel="manifest"/>
<link color="#5bbad5" href="/images/favicons/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#ffc40d" name="msapplication-TileColor"/>
<meta content="#ffffff" name="theme-color"/>
</meta></meta></meta></meta></meta></head>
<body>
<img alt="Ahead of AI logo" src="../images/ahead-of-ai-icon.png" style="display: none;"/>
<header class="site-header">
<div class="site-title" style="text-decoration: none; margin-top: 2em;">
<a href="/"><span style="color:black">Sebastian</span> <span style="color:#c5050c">Raschka</span> </a>
<a href="https://x.com/rasbt"><img alt="Twitter/X icon" height="20" src="../images/twitter-bw.jpg" style="padding-left:20px;"/></a>
<!--<a href="https://threads.net/@sebastianraschka"><img src="/images/logos/threads-logo-alt-small.png" height="20" style="padding-left:5px;" alt="Threads icon"></a>-->
<a href="https://www.linkedin.com/in/sebastianraschka/"><img alt="LinkedIn Icon" height="20" src="../images/linkedin-bw.jpg" style="padding-left:5px;"/></a>
<a href="https://github.com/rasbt"><img alt="GitHub icon" height="20" src="../images/github-bw.jpg" style="padding-left:5px;"/></a>
</div>
<!--  <div style="width:100%;height:50;float:left;margin-bottom:10px;">
        &nbsp;<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-bw.jpg" height="20"></a>-->
<!-- &nbsp;<a href="https://www.buymeacoffee.com/rasbt"><img src="/images/logos/coffee-bw.jpg" height="20"></a>-->
<!--&nbsp;<a href="https://mastodon.social/@SebRaschka"><img src="/images/logos/mastodon-bw.jpg" height="20"></a>-->
<!-- </div>-->
<div class="wrapper">
<nav class="site-nav">
<a class="menu-icon" href="#">
<svg viewbox="0 0 18 15">
<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" fill="#424242"></path>
<path d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" fill="#424242"></path>
<path d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" fill="#424242"></path>
</svg>
</a>
<div class="trigger">
<!--<script type="text/javascript">
          var total_images = 2;
          var random_number = Math.floor((Math.random()*total_images));
          var random_img = new Array();
          random_img[0] = '<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-1.jpg" height="20"></a>';
          random_img[1] = '<a href="https://linkedin.com/in/sebastianraschka"><img src="/images/logos/linkedin-1.jpg" height="20"></a>';
          document.write(random_img[random_number]);
          </script>-->
<span style="padding-left:0px;margin-left:0px;"></span>
<a class="page-link" href="https://magazine.sebastianraschka.com"><span style="color:#c5050c;"><img alt="Ahead of AI Logo" height="20" src="../images/ahead-of-ai-icon.png"/> Blog</span></a>
<!--<a class="page-link" href="/blog/index.html">Blog</a>-->
<a class="page-link" href="/books">Books</a>
<!--<a class="page-link" href="/newsletter">AI Newsletter</a>-->
<!--<a class="page-link" href="/teaching">Courses</a>-->
<a class="page-link" href="https://github.com/rasbt/LLMs-from-scratch">LLMs From Scratch</a>
<!--<a class="page-link" href="/publications">Research</a>-->
<a class="page-link" href="/elsewhere">Talks</a>
<a class="page-link" href="/contact">Contact</a>
<a class="page-link" href="/resources">More</a>
</div>
</nav>
</div>
</header>
<div class="page-content">
<div class="wrapper">
<!-- MathJax script for LaTeX rendering -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- Open Graph Metadata -->
<meta content="article" property="og:type"/>
<meta content="Chapter 04" property="og:title"/>
<meta content="" property="og:description"/>
<meta content="https://sebastianraschka.com" property="og:image"/>
<meta content="" property="og:image:alt"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch04/" property="og:url"/>
<meta content="Sebastian Raschka's Blog" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<!-- Twitter Metadata -->
<meta content="summary_large_image" name="twitter:card"/>
<meta content="Chapter 04" name="twitter:title"/>
<meta content="" name="twitter:description"/>
<meta content="https://sebastianraschka.com" name="twitter:image"/>
<meta content="" name="twitter:image:alt"/>
<div class="post">
<header class="post-header">
<h1 class="post-title" style="text-align: left;">Machine Learning Q and AI</h1>
<h2 class="post-subtitle">30 Essential Questions and Answers on Machine Learning and AI</h2>
<p>
      By Sebastian Raschka. <a href="#table-of-contents">Free to read</a>.
      Published by <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>.<br/>
      Copyright Â© 2024-2025 by Sebastian Raschka.
    </p>
<p>
<img alt="Machine Learning and Q and AI" class="right-image-shadow-30" src="../images/2023-ml-ai-beyond.jpg"/>
</p>
<blockquote>
      Machine learning and AI are moving at a rapid pace. Researchers and practitioners are constantly struggling to keep up with the breadth of concepts and techniques. This book provides bite-sized bits of knowledge for your journey from machine learning beginner to expert, covering topics from various machine learning areas. Even experienced machine learning researchers and practitioners will encounter something new that they can add to their arsenal of techniques.
    </blockquote>
<br/>
<p><strong>ð Print Book:</strong><br/>
<a href="https://amzn.to/4488ahe">Amazon</a><br/>
<a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</p>
<p><strong>ð Read Online:</strong><br/>
<a href="#table-of-contents">Full Book (Free)</a>
</p>
</header>
<article class="post-content">
<!-- Optional: Anchor Headings -->
<h1 id="chapter-4-the-lottery-ticket-hypothesis">
        
        
          Chapter 4: The Lottery Ticket Hypothesis <a href="#chapter-4-the-lottery-ticket-hypothesis"></a>
</h1>
<p><span id="ch04" label="ch04"></span></p>
<p><strong>What is the lottery ticket hypothesis,
and, if it holds true, how is it useful in
practice?</strong></p>
<p>The lottery ticket hypothesis is a concept in neural network training
that posits that within a randomly initialized neural network, there
exists a subnetwork (or âwinning ticketâ) that can, when trained
separately, achieve the same accuracy on a test set as the full network
after being trained for the same number of steps. This idea was first
proposed by Jonathan Frankle and Michael Carbin in 2018.</p>
<p>This chapter illustrates the lottery hypothesis step by step, then goes
over <em>weight pruning</em>, one of the key techniques to create smaller
subnetworks as part of the lottery hypothesis methodology. Lastly, it
discusses the practical implications and limitations of the hypothesis.</p>
<h2 id="the-lottery-ticket-training-procedure">
        
        
          The Lottery Ticket Training Procedure <a href="#the-lottery-ticket-training-procedure"></a>
</h2>
<p>FigureÂ <a data-reference="fig:ch04-fig01" data-reference-type="ref" href="#fig:ch04-fig01">1.1</a> illustrates the training
procedure for the lottery ticket hypothesis in four steps, which weâll
discuss one by one to help clarify the concept.</p>
<figure id="fig:ch04-fig01">
<img src="../images/ch04-fig01.png">
<figcaption>The lottery hypothesis training procedure</figcaption>
</img></figure>
<p>In FigureÂ <a data-reference="fig:ch04-fig01" data-reference-type="ref" href="#fig:ch04-fig01">1.1</a>, we start with a large neural
network that we train until convergence , meaning we put in our best
efforts to make it perform as well as possible on a target dataset (for
example, minimizing training loss and maximizing classification
accuracy). This large neural network is initialized as usual using small
random weights.</p>
<p>Next, as shown in
FigureÂ <a data-reference="fig:ch04-fig01" data-reference-type="ref" href="#fig:ch04-fig01">1.1</a>, we prune the neural networkâs
weight parameters , removing them from the network. We can do this by
setting the weights to zero to create sparse weight matrices. Here, we
can either prune individual weights, known as <em>unstructured</em> pruning, or
prune larger âchunksâ from the network, such as entire convolutional
filter channels. This is known as <em>structured</em> pruning.</p>
<p>The original lottery hypothesis approach follows a concept known as
<em>iterative magnitude pruning</em>, where the weights with the lowest
magnitudes are removed in an iterative fashion. (We will revisit this
concept in ChapterÂ <a data-reference="ch06" data-reference-type="ref" href="../ch06">[ch06]</a> when discussing techniques to reduce
overfitting.)</p>
<p>After the pruning step, we reset the weights to the original small
random values used in step 1 in
FigureÂ <a data-reference="fig:ch04-fig01" data-reference-type="ref" href="#fig:ch04-fig01">1.1</a> and train the pruned network .
Itâs worth emphasizing that we do not reinitialize the pruned network
with any small random weights (as is typical for iterative magnitude
pruning), and instead we reuse the weights from step 1.</p>
<p>We then repeat the pruning steps 2 through 4 until we reach the desired
network size. For example, in the original lottery ticket hypothesis
paper, the authors successfully reduced the network to 10 percent of its
original size without sacrificing classification accuracy. As a nice
bonus, the pruned (sparse) network, referred to as the <em>winning ticket</em>,
even demonstrated improved generalization performance compared to the
original (large and dense) network.</p>
<h2 id="practical-implications-and-limitations">
        
        
          Practical Implications and Limitations <a href="#practical-implications-and-limitations"></a>
</h2>
<p>If itâs possible to identify smaller subnetworks that have the same
predictive performance as their up-to-10-times-larger counterparts, this
can have significant implications for both neural training and
inference. Given the ever-growing size of modern neural network
architectures, this can help cut training costs and infrastructure.</p>
<p>Sound too good to be true? Maybe. If winning tickets can be identified
efficiently, this would be very useful in practice. However, at the time
of writing, there is no way to find the winning tickets without training
the original network. Including the pruning steps would make this even
more expensive than a regular training procedure. Moreover, after the
publication of the original paper, researchers found that the original
weight initialization may not work to find winning tickets for
larger-scale networks, and additional experimentation with the initial
weights of the pruned networks is required.</p>
<p>The good news is that winning tickets do exist. Even if itâs currently
not possible to identify them without training their larger neural
network counterparts, they can be used for more efficient inference
after training.</p>
<h3 id="exercises">
        
        
          Exercises <a href="#exercises"></a>
</h3>
<p>4-1. Suppose weâre trying out the lottery
ticket hypothesis approach and find that the performance of the
subnetwork is not very good (compared to the original network). What
next steps might we try?</p>
<p>4-2. The simplicity
and efficiency of the rectified linear unit (ReLU) activation function
have made it one of the most popular activation functions in neural
network training, particularly in deep learning, where it helps to
mitigate problems like the vanishing gradient. The ReLU activation
function is defined by the mathematical expression max(0, <em>x</em>). This
means that if the input <em>x</em> is positive, the function returns <em>x</em>, but
if the input is negative or 0, the function returns 0. How is the
lottery ticket hypothesis related to training a neural network with ReLU
activation functions?</p>
<h2 id="references">
        
        
          References <a href="#references"></a>
</h2>
<ul>
<li>
<p>The paper proposing the lottery ticket hypothesis: Jonathan Frankle
and Michael Carbin, âThe Lottery Ticket Hypothesis: Finding Sparse,
Trainable Neural Networksâ (2018), <a href="https://arxiv.org/abs/1803.03635">https://arxiv.org/abs/1803.03635</a>.</p>
</li>
<li>
<p>The paper proposing structured pruning for removing larger parts, such
as entire convolutional filters, from a network: Hao Li et al.,
âPruning Filters for Efficient ConvNetsâ (2016),
<a href="https://arxiv.org/abs/1608.08710">https://arxiv.org/abs/1608.08710</a>.</p>
</li>
<li>
<p>Follow-up work on the lottery hypothesis, showing that the original
weight initialization may not work to find winning tickets for
larger-scale networks, and additional experimentation with the initial
weights of the pruned networks is required: Jonathan Frankle
et al., âLinear Mode Connectivity and the Lottery Ticket Hypothesisâ
(2019), <a href="https://arxiv.org/abs/1912.05671">https://arxiv.org/abs/1912.05671</a>.</p>
</li>
<li>
<p>An improved lottery ticket hypothesis algorithm that finds smaller
networks that match the performance of a larger network exactly: Vivek
Ramanujan et al., âWhatâs Hidden in a Randomly Weighted Neural
Network?â (2020), <a href="https://arxiv.org/abs/1911.13299">https://arxiv.org/abs/1911.13299</a>.</p>
</li>
</ul>
</article>
<br/>
<hr/>
<div class="book-promotion" style="margin-top: 50px;">
<h2>Support the Author</h2>
<p>You can support the author in the following ways:</p>
<ul>
<li>
        Subscribe to <a href="https://magazine.sebastianraschka.com">Sebastian's Substack blog</a>
</li>
<li>
        Purchase a copy on
        <a href="https://amzn.to/4488ahe">Amazon</a> or
        <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</li>
<li>
        Write an <a href="https://amzn.to/4488ahe">Amazon review</a>
</li>
</ul>
</div>
<div style="margin-bottom: 50px;"></div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="wrapper">
<div class="footer-col-wrapper">
<div class="footer-col social-col">
<a href="https://magazine.sebastianraschka.com"><span><i class="fa fa-rss fa-2x"></i></span> </a>
<a href="/contact"><span><i class="fa fa-envelope fa-2x"></i></span> </a>
<a href="https://twitter.com/rasbt"> <span><i class="fa fa-twitter fa-2x"></i></span> </a>
<a href="https://youtube.com/c/SebastianRaschka"><span><i class="fa fa-youtube fa-2x"></i></span> </a>
<a href="https://github.com/rasbt"><span><i class="fa fa-github fa-2x"></i> </span></a>
<a href="https://scholar.google.com/citations?user=X4RCC0IAAAAJ&amp;hl=enrasbt"><span><i class="fa fa-google fa-2x"></i> </span></a>
<a href="https://linkedin.com/in/sebastianraschka"><span><i class="fa fa-linkedin fa-2x"></i> </span></a>
</div>
<div class="footer-col copyright-col">
<p>© 2013-2025 Sebastian Raschka</p>
</div>
</div>
</div>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BYQXBRPK81"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BYQXBRPK81');
</script>
</footer>

<script src="/js/anchor.min.js" type="text/javascript"></script>
<script>
    var selector = 'h2, h3, h4, h5, h6';
    /*
    anchors.options = {
      icon: '#',
      visible: 'always',
      placement: 'left',
      class: 'bb-anchor'
    }
    */
    anchors.add(selector);
  </script>
</body>
</html>
