<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width initial-scale=1" name="viewport">
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="Sebastian Raschka" name="author"/>
<meta content="
      Chapter 01
    " property="og:title"/>
<meta content="
        I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.

      " property="og:description"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch01/" property="og:url">
<meta content="Sebastian Raschka, PhD" property="og:site_name">
<meta content="en_US" property="og:locale">
<meta content="@rasbt" name="twitter:site">
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="twitter:description"/>
<meta content="article" property="og:type"/>
<meta content="" property="article:published_time"/>
<meta content="@rasbt" name="twitter:creator"/>
<meta content="Chapter 01" name="twitter:title"/>
<meta content="summary" name="twitter:card"/>
<meta content="" name="twitter:image"/>
<title>Chapter 01</title>
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="description"/>
<link href=" /css/combined_direct_no_sass.css" rel="stylesheet"/>
<link href=" /css/fork-awesome.min.css" rel="stylesheet"/>
<meta content="Chapter 01" property="og:title"/>
<meta content="article" property="og:type"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch01/" property="og:url"/>
<meta content="" property="og:image"/>
<meta content="" property="og:description"/>
<meta content="Sebastian Raschka, PhD" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<meta content="" property="fb:admins"/>
<meta content="" property="fb:app_id"/>
<link href="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch01/" rel="canonical"/>
<link href="/images/favicons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/favicons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/favicons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/site.webmanifest" rel="manifest"/>
<link color="#5bbad5" href="/images/favicons/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#ffc40d" name="msapplication-TileColor"/>
<meta content="#ffffff" name="theme-color"/>
</meta></meta></meta></meta></meta></head>
<body>
<img alt="Ahead of AI logo" src="../images/ahead-of-ai-icon.png" style="display: none;"/>
<header class="site-header">
<div class="site-title" style="text-decoration: none; margin-top: 2em;">
<a href="/"><span style="color:black">Sebastian</span> <span style="color:#c5050c">Raschka</span> </a>
<a href="https://x.com/rasbt"><img alt="Twitter/X icon" height="20" src="../images/twitter-bw.jpg" style="padding-left:20px;"/></a>
<!--<a href="https://threads.net/@sebastianraschka"><img src="/images/logos/threads-logo-alt-small.png" height="20" style="padding-left:5px;" alt="Threads icon"></a>-->
<a href="https://www.linkedin.com/in/sebastianraschka/"><img alt="LinkedIn Icon" height="20" src="../images/linkedin-bw.jpg" style="padding-left:5px;"/></a>
<a href="https://github.com/rasbt"><img alt="GitHub icon" height="20" src="../images/github-bw.jpg" style="padding-left:5px;"/></a>
</div>
<!--  <div style="width:100%;height:50;float:left;margin-bottom:10px;">
        &nbsp;<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-bw.jpg" height="20"></a>-->
<!-- &nbsp;<a href="https://www.buymeacoffee.com/rasbt"><img src="/images/logos/coffee-bw.jpg" height="20"></a>-->
<!--&nbsp;<a href="https://mastodon.social/@SebRaschka"><img src="/images/logos/mastodon-bw.jpg" height="20"></a>-->
<!-- </div>-->
<div class="wrapper">
<nav class="site-nav">
<a class="menu-icon" href="#">
<svg viewbox="0 0 18 15">
<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" fill="#424242"></path>
<path d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" fill="#424242"></path>
<path d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" fill="#424242"></path>
</svg>
</a>
<div class="trigger">
<!--<script type="text/javascript">
          var total_images = 2;
          var random_number = Math.floor((Math.random()*total_images));
          var random_img = new Array();
          random_img[0] = '<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-1.jpg" height="20"></a>';
          random_img[1] = '<a href="https://linkedin.com/in/sebastianraschka"><img src="/images/logos/linkedin-1.jpg" height="20"></a>';
          document.write(random_img[random_number]);
          </script>-->
<span style="padding-left:0px;margin-left:0px;"></span>
<a class="page-link" href="https://magazine.sebastianraschka.com"><span style="color:#c5050c;"><img alt="Ahead of AI Logo" height="20" src="../images/ahead-of-ai-icon.png"/> Blog</span></a>
<!--<a class="page-link" href="/blog/index.html">Blog</a>-->
<a class="page-link" href="/books">Books</a>
<!--<a class="page-link" href="/newsletter">AI Newsletter</a>-->
<!--<a class="page-link" href="/teaching">Courses</a>-->
<a class="page-link" href="https://github.com/rasbt/LLMs-from-scratch">LLMs From Scratch</a>
<!--<a class="page-link" href="/publications">Research</a>-->
<a class="page-link" href="/elsewhere">Talks</a>
<a class="page-link" href="/contact">Contact</a>
<a class="page-link" href="/resources">More</a>
</div>
</nav>
</div>
</header>
<div class="page-content">
<div class="wrapper">
<!-- MathJax script for LaTeX rendering -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- Open Graph Metadata -->
<meta content="article" property="og:type"/>
<meta content="Chapter 01" property="og:title"/>
<meta content="" property="og:description"/>
<meta content="https://sebastianraschka.com" property="og:image"/>
<meta content="" property="og:image:alt"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch01/" property="og:url"/>
<meta content="Sebastian Raschka's Blog" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<!-- Twitter Metadata -->
<meta content="summary_large_image" name="twitter:card"/>
<meta content="Chapter 01" name="twitter:title"/>
<meta content="" name="twitter:description"/>
<meta content="https://sebastianraschka.com" name="twitter:image"/>
<meta content="" name="twitter:image:alt"/>
<div class="post">
<header class="post-header">
<h1 class="post-title" style="text-align: left;">Machine Learning Q and AI</h1>
<h2 class="post-subtitle">30 Essential Questions and Answers on Machine Learning and AI</h2>
<p>
      By Sebastian Raschka. <a href="#table-of-contents">Free to read</a>.
      Published by <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>.<br/>
      Copyright Â© 2024-2025 by Sebastian Raschka.
    </p>
<p>
<img alt="Machine Learning and Q and AI" class="right-image-shadow-30" src="../images/2023-ml-ai-beyond.jpg"/>
</p>
<blockquote>
      Machine learning and AI are moving at a rapid pace. Researchers and practitioners are constantly struggling to keep up with the breadth of concepts and techniques. This book provides bite-sized bits of knowledge for your journey from machine learning beginner to expert, covering topics from various machine learning areas. Even experienced machine learning researchers and practitioners will encounter something new that they can add to their arsenal of techniques.
    </blockquote>
<br/>
<p><strong>ð Print Book:</strong><br/>
<a href="https://amzn.to/4488ahe">Amazon</a><br/>
<a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</p>
<p><strong>ð Read Online:</strong><br/>
<a href="#table-of-contents">Full Book (Free)</a>
</p>
</header>
<article class="post-content">
<!-- Optional: Anchor Headings -->
<h1 id="part-1-neural-networks-and-deep-learning">
        
        
          Part 1: Neural Networks and Deep Learning <a href="#part-1-neural-networks-and-deep-learning"></a>
</h1>
<h2 id="chapter-1-embeddings-latent-space-and-representations">
        
        
          Chapter 1: Embeddings, Latent Space, and Representations <a href="#chapter-1-embeddings-latent-space-and-representations"></a>
</h2>
<p><span id="ch01" label="ch01"></span></p>
<p><strong>In deep learning, we often use the terms <em>embedding vectors</em>,
<em>representations</em>, and <em>latent space</em>. What do these concepts have in
common, and how do they differ?</strong></p>
<p>While these three terms are often used interchangeably, we can make
subtle distinctions between them:</p>
<ul>
<li>
<p>Embedding vectors are representations of input data where similar
items are close to each other.</p>
</li>
<li>
<p>Latent vectors are intermediate representations of input data.</p>
</li>
<li>
<p>Representations are encoded versions of the original input.</p>
</li>
</ul>
<p>The following sections explore the relationship between embeddings,
latent vectors, and representations and how each functions to encode
information in machine learning contexts.</p>
<h3 id="embeddings">
        
        
          Embeddings <a href="#embeddings"></a>
</h3>
<p>Embedding vectors, or <em>embeddings</em> for short, encode relatively
high-dimensional data into relatively low-dimensional vectors.</p>
<p>We can apply embedding methods to create a continuous dense (non-sparse)
vector from a (sparse) one-hot encoding. <em>One-hot encoding</em> is a method
used to represent categorical data as binary vectors, where each
category is mapped to a vector containing 1 in the position
corresponding to the categoryâs index, and 0 in all other positions.
This ensures that the categorical values are represented in a way that
certain machine learning algorithms can process. For example, if we have
a categorical variable Color with three categories, Red, Green, and
Blue, the one-hot encoding would represent Red as [1, 0, 0], Green as
[0, 1, 0], and Blue as [0, 0, 1]. These one-hot encoded categorical
variables can then be mapped into continuous embedding vectors by
utilizing the learned weight matrix of an embedding layer or module.</p>
<p>We can also use embedding methods for dense data such as images. For
example, the last layers of a convolutional neural network may yield
embedding vectors, as illustrated in
FigureÂ <a data-reference="fig:ch01-fig01" data-reference-type="ref" href="#fig:ch01-fig01">1.1</a>.</p>
<figure id="fig:ch01-fig01">
<img src="../images/ch01-fig01.png">
<figcaption>An input embedding (left) and an embedding from a neural
network (right)</figcaption>
</img></figure>
<p>To be technically correct, all intermediate layer outputs of a neural
network could yield embedding vectors. Depending on the training
objective, the output layer may also produce useful embedding vectors.
For the sake of simplicity, the convolutional neural network in
FigureÂ <a data-reference="fig:ch01-fig01" data-reference-type="ref" href="#fig:ch01-fig01">1.1</a> associates the second-to-last
layer with embeddings.</p>
<p>Embeddings can have higher or lower numbers of dimensions than the
original input. For instance, using embeddings methods for extreme
expression, we can encode data into two-dimensional dense and continuous
representations for visualization purposes and clustering analysis, as
illustrated in
FigureÂ <a data-reference="fig:ch01-fig02" data-reference-type="ref" href="#fig:ch01-fig02">1.2</a>.</p>
<figure id="fig:ch01-fig02">
<img src="../images/ch01-fig02.png">
<figcaption>Mapping words (left) and images (right) to a two-dimensional
feature space</figcaption>
</img></figure>
<p>A fundamental property of embeddings is that they encode <em>distance</em> or
<em>similarity</em>. This means that embeddings capture the semantics of the
data such that similar inputs are close in the embeddings space.</p>
<p>For readers interested in a more formal explanation using mathematical
terminology, an embedding is an injective and structure-preserving map
between an input space <em>X</em> and the embedding space <em>Y</em>. This implies
that similar inputs will be located at points in close proximity within
the embedding space, which can be seen as the âstructure-preservingâ
characteristic of the embedding.</p>
<h3 id="latent-space">
        
        
          Latent Space <a href="#latent-space"></a>
</h3>
<p><em>Latent space</em> is typically used synonymously with <em>embedding space</em>,
the space into which embedding vectors are mapped.</p>
<p>Similar items can appear close in the latent space; however, this is not
a strict requirement. More loosely, we can think of the latent space as
any feature space that contains features, often compressed versions of
the original input features. These latent space features can be learned
by a neural network, such as an autoencoder that reconstructs input
images, as shown in
FigureÂ <a data-reference="fig:ch01-fig03" data-reference-type="ref" href="#fig:ch01-fig03">1.3</a>.</p>
<figure id="fig:ch01-fig03">
<img src="../images/ch01-fig03.png">
<figcaption>An autoencoder reconstructing the input image</figcaption>
</img></figure>
<p>The bottleneck in
FigureÂ <a data-reference="fig:ch01-fig03" data-reference-type="ref" href="#fig:ch01-fig03">1.3</a> represents a small, intermediate
neural network layer that encodes or maps the input image into a
lower-dimensional representation. We can think of the target space of
this mapping as a latent space. The training objective of the
autoencoder is to reconstruct the input image, that is, to minimize the
distance between the input and output images. In order to optimize the
training objective, the autoencoder may learn to place the encoded
features of similar inputs (for example, pictures of cats) close to each
other in the latent space, thus creating useful embedding vectors where
similar inputs are close in the embedding (latent) space.</p>
<h3 id="representation">
        
        
          Representation <a href="#representation"></a>
</h3>
<p>A <em>representation</em> is an encoded, typically intermediate form of an
input. For instance, an embedding vector or vector in the latent space
is a representation of the input, as previously discussed. However,
representations can also be produced by simpler procedures. For example,
one-hot encoded vectors are considered representations of an input.</p>
<p>The key idea is that the representation captures some essential features
or characteristics of the original data to make it useful for further
analysis or processing.</p>
<h3 id="exercises">
        
        
          Exercises <a href="#exercises"></a>
</h3>
<p>1-1. Suppose weâre training a convolutional
network with five convolutional layers followed by three fully connected
(FC) layers, similar to AlexNet
(<a href="https://en.wikipedia.org/wiki/AlexNet">https://en.wikipedia.org/wiki/AlexNet</a>), as illustrated in
FigureÂ <a data-reference="fig:ch01-fig04" data-reference-type="ref" href="#fig:ch01-fig04">[fig:ch01-fig04]</a>.</p>
<div class="minipage">
<img alt="image" src="../images/ch01-fig04.png">
<span id="fig:ch01-fig04" label="fig:ch01-fig04"></span>
</img></div>
<p>We can think of these fully connected layers as two hidden layers and an
output layer in a multilayer perceptron. Which of the neural network
layers can be utilized to produce useful embeddings? Interested readers
can find more details about the AlexNet architecture and implementation
in the original publication by Alex Krizhevsky, Ilya Sutskever, and
Geoffrey Hinton.</p>
<p>1-2. Name some types of
input representations that are not embeddings.</p>
<h3 id="references">
        
        
          References <a href="#references"></a>
</h3>
<ul>
<li>The original paper describing the AlexNet architecture and
implementation: Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton,
âImageNet Classification with Deep Convolutional Neural Networksâ
(2012),
<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a>.</li>
</ul>
</article>
<br/>
<hr/>
<div class="book-promotion" style="margin-top: 50px;">
<h2>Support the Author</h2>
<p>You can support the author in the following ways:</p>
<ul>
<li>
        Subscribe to <a href="https://magazine.sebastianraschka.com">Sebastian's Substack blog</a>
</li>
<li>
        Purchase a copy on
        <a href="https://amzn.to/4488ahe">Amazon</a> or
        <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</li>
<li>
        Write an <a href="https://amzn.to/4488ahe">Amazon review</a>
</li>
</ul>
</div>
<div style="margin-bottom: 50px;"></div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="wrapper">
<div class="footer-col-wrapper">
<div class="footer-col social-col">
<a href="https://magazine.sebastianraschka.com"><span><i class="fa fa-rss fa-2x"></i></span> </a>
<a href="/contact"><span><i class="fa fa-envelope fa-2x"></i></span> </a>
<a href="https://twitter.com/rasbt"> <span><i class="fa fa-twitter fa-2x"></i></span> </a>
<a href="https://youtube.com/c/SebastianRaschka"><span><i class="fa fa-youtube fa-2x"></i></span> </a>
<a href="https://github.com/rasbt"><span><i class="fa fa-github fa-2x"></i> </span></a>
<a href="https://scholar.google.com/citations?user=X4RCC0IAAAAJ&amp;hl=enrasbt"><span><i class="fa fa-google fa-2x"></i> </span></a>
<a href="https://linkedin.com/in/sebastianraschka"><span><i class="fa fa-linkedin fa-2x"></i> </span></a>
</div>
<div class="footer-col copyright-col">
<p>© 2013-2025 Sebastian Raschka</p>
</div>
</div>
</div>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BYQXBRPK81"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BYQXBRPK81');
</script>
</footer>

<script src="/js/anchor.min.js" type="text/javascript"></script>
<script>
    var selector = 'h2, h3, h4, h5, h6';
    /*
    anchors.options = {
      icon: '#',
      visible: 'always',
      placement: 'left',
      class: 'bb-anchor'
    }
    */
    anchors.add(selector);
  </script>
</body>
</html>
