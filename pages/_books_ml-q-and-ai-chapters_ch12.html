<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width initial-scale=1" name="viewport">
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="Sebastian Raschka" name="author"/>
<meta content="
      Chapter 12
    " property="og:title"/>
<meta content="
        I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.

      " property="og:description"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch12/" property="og:url">
<meta content="Sebastian Raschka, PhD" property="og:site_name">
<meta content="en_US" property="og:locale">
<meta content="@rasbt" name="twitter:site">
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="twitter:description"/>
<meta content="article" property="og:type"/>
<meta content="" property="article:published_time"/>
<meta content="@rasbt" name="twitter:creator"/>
<meta content="Chapter 12" name="twitter:title"/>
<meta content="summary" name="twitter:card"/>
<meta content="" name="twitter:image"/>
<title>Chapter 12</title>
<meta content="I'm an LLM Research Engineer with over a decade of experience in artificial intelligence. My work bridges academia and industry, with roles including senior staff at an AI company and a statistics professor. My expertise lies in LLM research and the development of high-performance AI systems, with a deep focus on practical, code-driven implementations.
" name="description"/>
<link href=" /css/combined_direct_no_sass.css" rel="stylesheet"/>
<link href=" /css/fork-awesome.min.css" rel="stylesheet"/>
<meta content="Chapter 12" property="og:title"/>
<meta content="article" property="og:type"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch12/" property="og:url"/>
<meta content="" property="og:image"/>
<meta content="" property="og:description"/>
<meta content="Sebastian Raschka, PhD" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<meta content="" property="fb:admins"/>
<meta content="" property="fb:app_id"/>
<link href="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch12/" rel="canonical"/>
<link href="/images/favicons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/favicons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/favicons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/site.webmanifest" rel="manifest"/>
<link color="#5bbad5" href="/images/favicons/safari-pinned-tab.svg" rel="mask-icon"/>
<meta content="#ffc40d" name="msapplication-TileColor"/>
<meta content="#ffffff" name="theme-color"/>
</meta></meta></meta></meta></meta></head>
<body>
<img alt="Ahead of AI logo" src="../images/ahead-of-ai-icon.png" style="display: none;"/>
<header class="site-header">
<div class="site-title" style="text-decoration: none; margin-top: 2em;">
<a href="/"><span style="color:black">Sebastian</span> <span style="color:#c5050c">Raschka</span> </a>
<a href="https://x.com/rasbt"><img alt="Twitter/X icon" height="20" src="../images/twitter-bw.jpg" style="padding-left:20px;"/></a>
<!--<a href="https://threads.net/@sebastianraschka"><img src="/images/logos/threads-logo-alt-small.png" height="20" style="padding-left:5px;" alt="Threads icon"></a>-->
<a href="https://www.linkedin.com/in/sebastianraschka/"><img alt="LinkedIn Icon" height="20" src="../images/linkedin-bw.jpg" style="padding-left:5px;"/></a>
<a href="https://github.com/rasbt"><img alt="GitHub icon" height="20" src="../images/github-bw.jpg" style="padding-left:5px;"/></a>
</div>
<!--  <div style="width:100%;height:50;float:left;margin-bottom:10px;">
        &nbsp;<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-bw.jpg" height="20"></a>-->
<!-- &nbsp;<a href="https://www.buymeacoffee.com/rasbt"><img src="/images/logos/coffee-bw.jpg" height="20"></a>-->
<!--&nbsp;<a href="https://mastodon.social/@SebRaschka"><img src="/images/logos/mastodon-bw.jpg" height="20"></a>-->
<!-- </div>-->
<div class="wrapper">
<nav class="site-nav">
<a class="menu-icon" href="#">
<svg viewbox="0 0 18 15">
<path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" fill="#424242"></path>
<path d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" fill="#424242"></path>
<path d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" fill="#424242"></path>
</svg>
</a>
<div class="trigger">
<!--<script type="text/javascript">
          var total_images = 2;
          var random_number = Math.floor((Math.random()*total_images));
          var random_img = new Array();
          random_img[0] = '<a href="https://twitter.com/rasbt"><img src="/images/logos/twitter-1.jpg" height="20"></a>';
          random_img[1] = '<a href="https://linkedin.com/in/sebastianraschka"><img src="/images/logos/linkedin-1.jpg" height="20"></a>';
          document.write(random_img[random_number]);
          </script>-->
<span style="padding-left:0px;margin-left:0px;"></span>
<a class="page-link" href="https://magazine.sebastianraschka.com"><span style="color:#c5050c;"><img alt="Ahead of AI Logo" height="20" src="../images/ahead-of-ai-icon.png"/> Blog</span></a>
<!--<a class="page-link" href="/blog/index.html">Blog</a>-->
<a class="page-link" href="/books">Books</a>
<!--<a class="page-link" href="/newsletter">AI Newsletter</a>-->
<!--<a class="page-link" href="/teaching">Courses</a>-->
<a class="page-link" href="https://github.com/rasbt/LLMs-from-scratch">LLMs From Scratch</a>
<!--<a class="page-link" href="/publications">Research</a>-->
<a class="page-link" href="/elsewhere">Talks</a>
<a class="page-link" href="/contact">Contact</a>
<a class="page-link" href="/resources">More</a>
</div>
</nav>
</div>
</header>
<div class="page-content">
<div class="wrapper">
<!-- MathJax script for LaTeX rendering -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<!-- Open Graph Metadata -->
<meta content="article" property="og:type"/>
<meta content="Chapter 12" property="og:title"/>
<meta content="" property="og:description"/>
<meta content="https://sebastianraschka.com" property="og:image"/>
<meta content="" property="og:image:alt"/>
<meta content="https://sebastianraschka.com/books/ml-q-and-ai-chapters/ch12/" property="og:url"/>
<meta content="Sebastian Raschka's Blog" property="og:site_name"/>
<meta content="en_US" property="og:locale"/>
<!-- Twitter Metadata -->
<meta content="summary_large_image" name="twitter:card"/>
<meta content="Chapter 12" name="twitter:title"/>
<meta content="" name="twitter:description"/>
<meta content="https://sebastianraschka.com" name="twitter:image"/>
<meta content="" name="twitter:image:alt"/>
<div class="post">
<header class="post-header">
<h1 class="post-title" style="text-align: left;">Machine Learning Q and AI</h1>
<h2 class="post-subtitle">30 Essential Questions and Answers on Machine Learning and AI</h2>
<p>
      By Sebastian Raschka. <a href="#table-of-contents">Free to read</a>.
      Published by <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>.<br/>
      Copyright Â© 2024-2025 by Sebastian Raschka.
    </p>
<p>
<img alt="Machine Learning and Q and AI" class="right-image-shadow-30" src="../images/2023-ml-ai-beyond.jpg"/>
</p>
<blockquote>
      Machine learning and AI are moving at a rapid pace. Researchers and practitioners are constantly struggling to keep up with the breadth of concepts and techniques. This book provides bite-sized bits of knowledge for your journey from machine learning beginner to expert, covering topics from various machine learning areas. Even experienced machine learning researchers and practitioners will encounter something new that they can add to their arsenal of techniques.
    </blockquote>
<br/>
<p><strong>ð Print Book:</strong><br/>
<a href="https://amzn.to/4488ahe">Amazon</a><br/>
<a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</p>
<p><strong>ð Read Online:</strong><br/>
<a href="#table-of-contents">Full Book (Free)</a>
</p>
</header>
<article class="post-content">
<!-- Optional: Anchor Headings -->
<h1 id="chapter-12-fully-connected-and-convolutional-layers">
        
        
          Chapter 12: Fully Connected and Convolutional Layers <a href="#chapter-12-fully-connected-and-convolutional-layers"></a>
</h1>
<p><span id="ch12" label="ch12"></span></p>
<p><strong>Under which circumstances can we replace fully connected layers with
convolutional layers to perform the same computation?</strong></p>
<p>Replacing fully connected layers with convolutional layers can offer
advantages in terms of hardware optimization, such as by utilizing
specialized hardware accelerators for convolution operations. This can
be particularly relevant for edge devices.</p>
<p>There are exactly two scenarios in which fully connected layers and
convolutional layers are equivalent: when the size of the convolutional
filter is equal to the size of the receptive field and when the size of
the convolutional filter is 1. As an illustration of these two
scenarios, consider a fully connected layer with two input and four
output units, as shown in
FigureÂ <a data-reference="fig:ch12-fig01" data-reference-type="ref" href="#fig:ch12-fig01">1.1</a>.</p>
<figure id="fig:ch12-fig01">
<img src="../images/ch12-fig01.png">
<figcaption>Four inputs and<br>
two outputs connected via<br>
eight weight parameters</br></br></figcaption>
</img></figure>
<p>The fully connected layer in this figure consists of eight weights and
two bias units. We can compute the output nodes via the following dot
products:</p>
<p>Node 1</p>

\[w_{1, 1} \times x_1 + w_{1, 2} \times x_2 + w_{1, 3} \times x_3 + w_{1, 4} \times x_4 + b_1\]

<p>Node 2</p>

\[w_{2, 1} \times x_1 + w_{2, 2} \times x_2 + w_{2, 3} \times x_3 + w_{2, 4} \times x_4 + b_2\]

<p>The following two sections illustrate scenarios in which convolutional
layers can be defined to produce exactly the same computation as the
fully connected layer described.</p>
<h2 id="when-the-kernel-and-input-sizes-are-equal">
        
        
          When the Kernel and Input Sizes Are Equal <a href="#when-the-kernel-and-input-sizes-are-equal"></a>
</h2>
<p>Letâs start with the first scenario, where the size of the convolutional
filter is equal to the size of the receptive field. Recall from
ChapterÂ <a data-reference="ch11" data-reference-type="ref" href="../ch11">[ch11]</a> how we compute a number of parameters
in a convolutional kernel with one input channel and multiple output
channels. We have a kernel size of 2\(\times\)<!-- -->2, one input
channel, and two output channels. The input size is also
2\(\times\)<!-- -->2, a reshaped version of the four inputs depicted in
FigureÂ <a data-reference="fig:ch12-fig02" data-reference-type="ref" href="#fig:ch12-fig02">1.2</a>.</p>
<figure id="fig:ch12-fig02">
<img src="../images/ch12-fig02.png">
<figcaption>A convolutional layer with a 2Ã2 kernel<br>
that equals the input size and two output channels</br></figcaption>
</img></figure>
<p>If the convolutional kernel dimensions equal the input size, as depicted
in FigureÂ <a data-reference="fig:ch12-fig02" data-reference-type="ref" href="#fig:ch12-fig02">1.2</a>, there is no sliding window
mechanism in the convolutional layer. For the first output channel, we
have the following set of weights:</p>

\[{W}_1 = \begin{bmatrix}
w_{1, 1} &amp; w_{1, 2}\\
w_{1, 3} &amp; w_{1, 4}
\end{bmatrix}\]

<p>For the second output channel, we have the following set of weights:</p>

\[{W}_2 = \begin{bmatrix}
w_{2, 1} &amp; w_{2, 2}\\
w_{2, 3} &amp; w_{2, 4}
\end{bmatrix}\]

<p>If the inputs are organized as</p>

\[{x} = \begin{bmatrix}
x_{1} &amp; x_{2}\\
x_{3} &amp; x_{4}
\end{bmatrix}\]

<p>we calculate the first output channel as <em>o</em><sub>1</sub> =
\(\sum_i\)(<em>W</em><sub>1</sub> * <strong>x</strong>)<em><sub>i</sub></em> + <em>b</em><sub>1</sub>,
where the convolutional operator * is equal to an element-wise
multiplication. In other words, we perform an element-wise
multiplication between two matrices, <em>W</em><sub>1</sub> and <strong>x</strong>, and then
compute the output as the sum over these elements; this equals the dot
product in the fully connected layer. Lastly, we add the bias unit. The
computation for the second output channel works analogously:
<em>o</em><sub>2</sub> = \(\sum_i\)(<em>W</em><sub>2</sub> * <strong>x</strong>)<em><sub>i</sub></em> +
<em>b</em><sub>2</sub>.</p>
<p>As a bonus, the supplementary materials for this book include PyTorch
code to show this equivalence with a hands-on example in the
<code class="language-plaintext highlighter-rouge">supplementary/q12-fc-cnn-equivalence</code> subfolder at
<a href="https://github.com/rasbt/MachineLearning-QandAI-book">https://github.com/rasbt/MachineLearning-QandAI-book</a>.</p>
<h2 id="when-the-kernel-size-is-1">
        
        
          When the Kernel Size Is 1 <a href="#when-the-kernel-size-is-1"></a>
</h2>
<p>The second scenario assumes that we reshape the input into an input
âimageâ with \(1\times1\) dimensions where the number of âcolor
channelsâ equals the number of input features, as depicted in
FigureÂ <a data-reference="fig:ch12-fig03" data-reference-type="ref" href="#fig:ch12-fig03">1.3</a>.</p>
<figure id="fig:ch12-fig03">
<img src="../images/ch12-fig03.png">
<figcaption>The number of output nodes equals the number<br>
of channels if the kernel size is equal to the input size.</br></figcaption>
</img></figure>
<p>Each kernel consists of a stack of weights equal to the number of input
channels. For instance, for the first output layer, the weights are</p>

\[{W}_1 = [ w^{(1)}_{1} w^{(2)}_{1} w^{(3)}_{1} w^{(4)}_{1}]\]

<p>while the weights for the second channel are:</p>

\[{W}_2 = [ w^{(1)}_{2} w^{(2)}_{2} w^{(3)}_{2} w^{(4)}_{2}]\]

<p>To get a better intuitive understanding of this computation, check out
the illustrations in ChapterÂ <a data-reference="ch11" data-reference-type="ref" href="../ch11">[ch11]</a>, which describe how to compute the
parameters in a convolutional layer.</p>
<h2 id="recommendations">
        
        
          Recommendations <a href="#recommendations"></a>
</h2>
<p>The fact that fully connected layers can be implemented as equivalent
convolutional layers does not have immediate performance or other
advantages on standard computers. However, replacing fully connected
layers with convolutional layers can offer advantages in combination
with developing specialized hardware accelerators for convolution
operations.</p>
<p>Moreover, understanding the scenarios where fully connected layers are equivalent to convolutional layers aids in understanding
the mechanics of these layers. It also lets us implement convolutional neural networks without any use of fully connected layers,
if desired, to simplify code implementations.</p>
<h3 id="exercises">
        
        
          Exercises <a href="#exercises"></a>
</h3>
<p>12-1. How would increasing the stride affect
the equivalence discussed in this chapter?</p>
<p>12-2. Does padding affect the equivalence between
fully connected layers and convolutional layers?</p>
</article>
<br/>
<hr/>
<div class="book-promotion" style="margin-top: 50px;">
<h2>Support the Author</h2>
<p>You can support the author in the following ways:</p>
<ul>
<li>
        Subscribe to <a href="https://magazine.sebastianraschka.com">Sebastian's Substack blog</a>
</li>
<li>
        Purchase a copy on
        <a href="https://amzn.to/4488ahe">Amazon</a> or
        <a href="https://nostarch.com/machine-learning-q-and-ai">No Starch Press</a>
</li>
<li>
        Write an <a href="https://amzn.to/4488ahe">Amazon review</a>
</li>
</ul>
</div>
<div style="margin-bottom: 50px;"></div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="wrapper">
<div class="footer-col-wrapper">
<div class="footer-col social-col">
<a href="https://magazine.sebastianraschka.com"><span><i class="fa fa-rss fa-2x"></i></span> </a>
<a href="/contact"><span><i class="fa fa-envelope fa-2x"></i></span> </a>
<a href="https://twitter.com/rasbt"> <span><i class="fa fa-twitter fa-2x"></i></span> </a>
<a href="https://youtube.com/c/SebastianRaschka"><span><i class="fa fa-youtube fa-2x"></i></span> </a>
<a href="https://github.com/rasbt"><span><i class="fa fa-github fa-2x"></i> </span></a>
<a href="https://scholar.google.com/citations?user=X4RCC0IAAAAJ&amp;hl=enrasbt"><span><i class="fa fa-google fa-2x"></i> </span></a>
<a href="https://linkedin.com/in/sebastianraschka"><span><i class="fa fa-linkedin fa-2x"></i> </span></a>
</div>
<div class="footer-col copyright-col">
<p>© 2013-2025 Sebastian Raschka</p>
</div>
</div>
</div>
<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-BYQXBRPK81"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BYQXBRPK81');
</script>
</footer>

<script src="/js/anchor.min.js" type="text/javascript"></script>
<script>
    var selector = 'h2, h3, h4, h5, h6';
    /*
    anchors.options = {
      icon: '#',
      visible: 'always',
      placement: 'left',
      class: 'bb-anchor'
    }
    */
    anchors.add(selector);
  </script>
</body>
</html>
