# Table of Contents

- [Introduction](./introduction/_books_ml-q-and-ai-chapters_introduction.md)

## Part I: Neural Networks and Deep Learning

- [Chapter 1: Embeddings, Latent Space, and Representations](./chapters_ch01/_books_ml-q-and-ai-chapters_ch01.md)
- [Chapter 2: Self-Supervised Learning](./chapters_ch02/_books_ml-q-and-ai-chapters_ch02.md)
- [Chapter 3: Few-Shot Learning](./chapters_ch03/_books_ml-q-and-ai-chapters_ch03.md)
- [Chapter 4: The Lottery Ticket  Hypothesis](./chapters_ch04/_books_ml-q-and-ai-chapters_ch04.md)
- [Chapter 5: Reducing Overfitting with Data](./chapters_ch05/_books_ml-q-and-ai-chapters_ch05.md)
- [Chapter 6: Reducing Overfitting with Model Modifications](./chapters_ch06/_books_ml-q-and-ai-chapters_ch06.md)
- [Chapter 7: Multi-GPU Training Paradigms](./chapters_ch07/_books_ml-q-and-ai-chapters_ch07.md)
- [Chapter 8: The Success of Transformers](./chapters_ch08/_books_ml-q-and-ai-chapters_ch08.md)
- [Chapter 9: Generative AI Models](./chapters_ch09/_books_ml-q-and-ai-chapters_ch09.md)
- [Chapter 10: Sources of Randomness](./chapters_ch10/_books_ml-q-and-ai-chapters_ch10.md)

## Part II: Computer Vision

- [Chapter 11: Calculating the Number of Parameters](./chapters_ch11/_books_ml-q-and-ai-chapters_ch11.md)
- [Chapter 12: Fully Connected and Convolutional Layers](./chapters_ch12/_books_ml-q-and-ai-chapters_ch12.md)
- [Chapter 13: Large Training Sets for Vision Transformers](./chapters_ch13/_books_ml-q-and-ai-chapters_ch13.md)

## Part III: Natural Language Processing

- [Chapter 14: The Distributional Hypothesis](./chapters_ch14/_books_ml-q-and-ai-chapters_ch14.md)
- [Chapter 15: Data Augmentation for Text](./chapters_ch15/_books_ml-q-and-ai-chapters_ch15.md)
- [Chapter 16: Self-Attention](./chapters_ch16/_books_ml-q-and-ai-chapters_ch16.md)
- [Chapter 17: Encoder- and Decoder-Style Transformers](./chapters_ch17/_books_ml-q-and-ai-chapters_ch17.md)
- [Chapter 18: Using and Fine-Tuning Pretrained Transformers](./chapters_ch18/_books_ml-q-and-ai-chapters_ch18.md)
- [Chapter 19: Evaluating Generative Large Language Models](./chapters_ch19/_books_ml-q-and-ai-chapters_ch19.md)

## Part IV: Production and Deployment

- [Chapter 20: Stateless and Stateful Training](./chapters_ch20/_books_ml-q-and-ai-chapters_ch20.md)
- [Chapter 21: Data-Centric AI](./chapters_ch21/_books_ml-q-and-ai-chapters_ch21.md)
- [Chapter 22: Speeding Up Inference](./chapters_ch22/_books_ml-q-and-ai-chapters_ch22.md)
- [Chapter 23: Data Distribution Shifts](./chapters_ch23/_books_ml-q-and-ai-chapters_ch23.md)

## Part V: Predictive Performance and Model Evaluation

- [Chapter 24: Poisson and Ordinal Regression](./chapters_ch24/_books_ml-q-and-ai-chapters_ch24.md)
- [Chapter 25: Confidence Intervals](./chapters_ch25/_books_ml-q-and-ai-chapters_ch25.md)
- [Chapter 26: Confidence Intervals vs. Conformal Predictions](./chapters_ch26/_books_ml-q-and-ai-chapters_ch26.md)
- [Chapter 27: Proper Metrics](./chapters_ch27/_books_ml-q-and-ai-chapters_ch27.md)
- [Chapter 28: The k in k-Fold Cross-Validation](./chapters_ch28/_books_ml-q-and-ai-chapters_ch28.md)
- [Chapter 29: Training and Test Set Discordance](./chapters_ch29/_books_ml-q-and-ai-chapters_ch29.md)
- [Chapter 30: Limited Labeled Data](./chapters_ch30/_books_ml-q-and-ai-chapters_ch30.md)

